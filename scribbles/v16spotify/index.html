<!doctype html><html lang=en><head><title>Replicating v16 spotify recommendation system :: :)</title>
<meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="the initial model for candidate selection was WRMF(weight regularized matrix factorization)
from the name its pretty easy to assume what it&amp;rsquo;s supposed to be doing
basically matrix factorization as used in regular collaborative filtering problems
where the userxitem ie preferences/ratings or whatever floats your boat is factorized into user and item embeddings that can be used for subsequent predictions
I think the regularization employed here is just for more efficiently learning (something i think is pretty relevant in this case since we&amp;rsquo;ve got like 20k&amp;hellip;."><meta name=keywords content><meta name=robots content="noodp"><link rel=canonical href=https://aybdee.xyz/scribbles/v16spotify/><link rel=stylesheet href=https://aybdee.xyz/styles.css><link rel="shortcut icon" href=https://aybdee.xyz/img/theme-colors/pink.png><link rel=apple-touch-icon href=https://aybdee.xyz/img/theme-colors/pink.png><meta name=twitter:card content="summary"><meta name=twitter:site content><meta name=twitter:creator content="abundance"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="og:title" content="Replicating v16 spotify recommendation system"><meta property="og:description" content="the initial model for candidate selection was WRMF(weight regularized matrix factorization)
from the name its pretty easy to assume what it&amp;rsquo;s supposed to be doing
basically matrix factorization as used in regular collaborative filtering problems
where the userxitem ie preferences/ratings or whatever floats your boat is factorized into user and item embeddings that can be used for subsequent predictions
I think the regularization employed here is just for more efficiently learning (something i think is pretty relevant in this case since we&amp;rsquo;ve got like 20k&amp;hellip;."><meta property="og:url" content="https://aybdee.xyz/scribbles/v16spotify/"><meta property="og:site_name" content=":)"><meta property="og:image" content="https://aybdee.xyz/"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="627"><meta property="article:published_time" content="2023-05-15 10:57:12 +0100 +0100"></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-E4TTEGH2X0"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-E4TTEGH2X0")</script><body class=pink><div class="container center headings--one-size"><header class=header><div class=header__inner><div class=header__logo><a href=/><div class=logo>Abd</div></a></div><ul class="menu menu--mobile"><li class=menu__trigger>Menu&nbsp;▾</li><li><ul class=menu__dropdown><li><a href=/about>About</a></li><li><a href=/musings>Musings</a></li><li><a href=/posts>Posts</a></li><li><a href=/scribbles>Scribbles</a></li></ul></li></ul></div><nav class=navigation-menu><ul class="navigation-menu__inner menu--desktop"><li><a href=/about>About</a></li><li><a href=/musings>Musings</a></li><li><a href=/posts>Posts</a></li><li><a href=/scribbles>Scribbles</a></li></ul></nav></header><div class=content><article class=post><h1 class=post-title><a href=https://aybdee.xyz/scribbles/v16spotify/>Replicating v16 spotify recommendation system</a></h1><div class=post-meta><time class=post-date>2023-05-15</time><span class=post-author>abundance</span></div><span class=post-tags>#<a href=https://aybdee.xyz/tags/research-paper/>research paper</a>&nbsp;
#<a href=https://aybdee.xyz/tags/machine-learning/>machine learning</a>&nbsp;
#<a href=https://aybdee.xyz/tags/spotify/>spotify</a>&nbsp;</span><div class=post-content><div><p>the initial model for candidate selection was WRMF(weight regularized matrix factorization)<br>from the name its pretty easy to assume what it&rsquo;s supposed to be doing</p><p>basically matrix factorization as used in regular collaborative filtering problems</p><p>where the userxitem ie preferences/ratings or whatever floats your boat is factorized into user and item embeddings that can be used for subsequent predictions</p><p>I think the regularization employed here is just for more efficiently learning (something i think is pretty relevant in this case since we&rsquo;ve got like 20k&mldr;..)
the creators of v16 link to a paper that more or less describes their specific approach to WRMF
(Collaborative Filtering for Immediate Feedback Datasets)</p><p>it starts by distinguishing what immediate feedback recommendation problems are and the unique challenges that come as a result</p><p>(can&rsquo;t really do the whole thing that would take forever)</p><p>for the most part,Implicit feedback problems occur when there aren&rsquo;t any explicit(for lack of better word) metrics by which users rank the items that they interact with (usually in the form of a star rating or a ranking or something like that)
instead what you have is just the data on how the user interacts with items , so stuff like how many times they bought something or clickedon a product)</p><p>generating recommendations for users from implicit feedback data is significantly different
one because there isn&rsquo;t any way of quantifying negative preference with the data
(in a ranking system a 1 star rating means the user probably dislikes the product but there&rsquo;s no such thing as negatively clicking a lick)</p><p>and then there&rsquo;s also the fact that these kinds of data tend to be more noisy because not all interactions might come from the user
(this is something that is largely mitigated with rating systems because most people ranking and starring products are doing it to show their personal preference in some way and would rarely bother ranking when someone else is involved)</p><p>lastly is just the increase in the overall complexity of the model for solving the problem
with a simple numerical rating the problem is just to predict a specific score and
the metrics for model success are pretty clear
something like root mean square could probably suffice</p><p>with Implicit feedback it&rsquo;s a little different
since we&rsquo;re working with user interactions
the model is predicting the likelihood of the user performing a certain interaction
for all possible interactions</p><p>(that means we&rsquo;ll have to consider things like availability of the item(whether the interaction can even happen in the first place),
competition with other items, and repeat feedback(not quite sure what this is))</p></div></div></article></div><footer class=footer><div class=footer__inner><div class=copyright><span>© 2024 aybdee</span>
<span>:: something random i guess</span></div></div></footer><script type=text/javascript src=/bundle.min.js></script></div></body></html>